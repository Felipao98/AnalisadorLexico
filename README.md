# üß† Analisador L√©xico em Python

Este projeto √© um analisador l√©xico simples escrito em Python, projetado para dividir uma entrada de c√≥digo-fonte em **tokens l√©xicos**, como identificadores, n√∫meros inteiros, operadores e pontua√ß√µes b√°sicas.

---

## ‚úÖ Funcionalidades

- Reconhece identificadores (`vari√°veis`, `x`, `total`, etc.).
- Reconhece n√∫meros inteiros (`123`, `42`, etc.).
- Suporte a operadores b√°sicos (`+`, `-`, `*`, `/`, `=`).
- Identifica par√™nteses e ponto e v√≠rgula.
- Ignora espa√ßos e quebras de linha.
- Gera erro para tokens inv√°lidos (n√£o reconhecidos).

---

## ‚ö° Atalhos

- A estrutura `(?P<TOKEN>padr√£o)` nomeia cada express√£o regular, facilitando a identifica√ß√£o do tipo de token capturado.
- O uso de `token_specification` como lista de tuplas torna f√°cil a adi√ß√£o e manuten√ß√£o de novos tokens.
- A fun√ß√£o `re.finditer()` percorre a entrada buscando todos os tokens de forma cont√≠nua e eficiente.
- Tokens como espa√ßos e quebras de linhas s√£o ignorados diretamente dentro do loop, simplificando o fluxo de an√°lise.

---

## üìê Especifica√ß√µes

- **Linguagem:** Python
- **Bibliotecas:** `re` (express√µes regulares)
- **Tokens suportados:**
  - `ID` ‚Üí identificadores
  - `NUM` ‚Üí n√∫meros inteiros
  - `OP` ‚Üí operadores matem√°ticos e de atribui√ß√£o
  - `LPAREN`, `RPAREN` ‚Üí par√™nteses
  - `SEMI` ‚Üí ponto e v√≠rgula
- **Sa√≠da:** lista de tuplas `(tipo, valor)`

---

## üö´ Limita√ß√µes

- N√£o reconhece n√∫meros decimais (ex: `3.14` causa erro).
- Palavras-chave (`if`, `else`, `while`) s√£o tratadas como identificadores comuns.
- N√£o h√° suporte para:
  - Strings
  - Coment√°rios
  - Caracteres especiais
  - Operadores compostos (`>=`, `==`, etc.)
- O analisador √© **apenas l√©xico**, n√£o possui an√°lise sint√°tica ou sem√¢ntica.
- A entrada precisa estar em **formato texto simples**, lida diretamente como `string` ou com pequena adapta√ß√£o para leitura de arquivos.

---

# üìò Analisador Sint√°tico LL(1)

Este projeto tamb√©m inclui um **analisador sint√°tico** baseado em **gram√°tica LL(1)** que utiliza a sa√≠da do analisador l√©xico para validar estruturas sint√°ticas de uma linguagem simples.

---

## üîß Funcionalidades

- Recebe como entrada a lista de tokens do analisador l√©xico.
- Permite definir sua pr√≥pria **gram√°tica** com produ√ß√µes e regras.
- Calcula automaticamente os conjuntos `FIRST` e `FOLLOW`.
- Gera e exibe a **tabela preditiva (tabela M)** para an√°lise LL(1).
- Informa os passos para transformar a gram√°tica para forma LL(1), se necess√°rio.
- Pode ser expandido para reconhecer v√°rias senten√ßas a partir da gram√°tica fornecida.

---

## üí° Exemplo de uso

```python
from lexer import lexer
from parser_ll1 import ParserGenerator

tokens = lexer("x = 3 + y * (2 - z);")

grammar = {
    'S': [['ID', 'OP', 'E', 'SEMI']],
    'E': [['T', 'E_']],
    'E_': [['OP', 'T', 'E_'], ['Œµ']],
    'T': [['F', 'T_']],
    'T_': [['OP', 'F', 'T_'], ['Œµ']],
    'F': [['NUM'], ['ID'], ['LPAREN', 'E', 'RPAREN']]
}

pg = ParserGenerator(grammar, start_symbol='S')
pg.print_first_follow()
pg.print_parse_table()
